{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.990904226859283,
  "eval_steps": 500,
  "global_step": 2335,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.21401819154628143,
      "grad_norm": 0.15026050806045532,
      "learning_rate": 9.7e-05,
      "loss": 2.3558,
      "step": 100
    },
    {
      "epoch": 0.42803638309256287,
      "grad_norm": 0.1649676114320755,
      "learning_rate": 9.953596017399939e-05,
      "loss": 0.174,
      "step": 200
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 0.16188660264015198,
      "learning_rate": 9.809523998387856e-05,
      "loss": 0.1528,
      "step": 300
    },
    {
      "epoch": 0.8560727661851257,
      "grad_norm": 0.17789211869239807,
      "learning_rate": 9.570581389673437e-05,
      "loss": 0.1474,
      "step": 400
    },
    {
      "epoch": 1.06848582129481,
      "grad_norm": 0.15059112012386322,
      "learning_rate": 9.241481469785151e-05,
      "loss": 0.1457,
      "step": 500
    },
    {
      "epoch": 1.2825040128410916,
      "grad_norm": 0.13799981772899628,
      "learning_rate": 8.828715921367945e-05,
      "loss": 0.1454,
      "step": 600
    },
    {
      "epoch": 1.496522204387373,
      "grad_norm": 0.13778096437454224,
      "learning_rate": 8.340426779059816e-05,
      "loss": 0.1372,
      "step": 700
    },
    {
      "epoch": 1.7105403959336543,
      "grad_norm": 0.12646369636058807,
      "learning_rate": 7.786245823238935e-05,
      "loss": 0.1396,
      "step": 800
    },
    {
      "epoch": 1.9245585874799358,
      "grad_norm": 0.1627015471458435,
      "learning_rate": 7.1771045876908e-05,
      "loss": 0.1384,
      "step": 900
    },
    {
      "epoch": 2.13697164258962,
      "grad_norm": 0.13591432571411133,
      "learning_rate": 6.525018728901962e-05,
      "loss": 0.1333,
      "step": 1000
    },
    {
      "epoch": 2.3509898341359015,
      "grad_norm": 0.14183130860328674,
      "learning_rate": 5.842851010418373e-05,
      "loss": 0.1342,
      "step": 1100
    },
    {
      "epoch": 2.5650080256821832,
      "grad_norm": 0.13705246150493622,
      "learning_rate": 5.144057577536354e-05,
      "loss": 0.1362,
      "step": 1200
    },
    {
      "epoch": 2.7790262172284645,
      "grad_norm": 0.13478659093379974,
      "learning_rate": 4.4424225272018494e-05,
      "loss": 0.1346,
      "step": 1300
    },
    {
      "epoch": 2.993044408774746,
      "grad_norm": 0.1532946676015854,
      "learning_rate": 3.7517860088773375e-05,
      "loss": 0.133,
      "step": 1400
    },
    {
      "epoch": 3.20545746388443,
      "grad_norm": 0.14719633758068085,
      "learning_rate": 3.085771219741037e-05,
      "loss": 0.1292,
      "step": 1500
    },
    {
      "epoch": 3.4194756554307117,
      "grad_norm": 0.14407576620578766,
      "learning_rate": 2.4575156793930217e-05,
      "loss": 0.1274,
      "step": 1600
    },
    {
      "epoch": 3.633493846976993,
      "grad_norm": 0.1681312620639801,
      "learning_rate": 1.8794120848271206e-05,
      "loss": 0.1335,
      "step": 1700
    },
    {
      "epoch": 3.8475120385232744,
      "grad_norm": 0.14768175780773163,
      "learning_rate": 1.3628638574513336e-05,
      "loss": 0.1306,
      "step": 1800
    },
    {
      "epoch": 4.059925093632959,
      "grad_norm": 0.1430405080318451,
      "learning_rate": 9.180602041304676e-06,
      "loss": 0.1294,
      "step": 1900
    },
    {
      "epoch": 4.27394328517924,
      "grad_norm": 0.13469094038009644,
      "learning_rate": 5.537751292995696e-06,
      "loss": 0.132,
      "step": 2000
    },
    {
      "epoch": 4.487961476725522,
      "grad_norm": 0.13379909098148346,
      "learning_rate": 2.771943627482282e-06,
      "loss": 0.1285,
      "step": 2100
    },
    {
      "epoch": 4.701979668271803,
      "grad_norm": 0.15145725011825562,
      "learning_rate": 9.377361702343212e-07,
      "loss": 0.1295,
      "step": 2200
    },
    {
      "epoch": 4.915997859818084,
      "grad_norm": 0.15815219283103943,
      "learning_rate": 7.130970404112258e-08,
      "loss": 0.1271,
      "step": 2300
    }
  ],
  "logging_steps": 100,
  "max_steps": 2335,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.04093535404032e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
