{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.990904226859283,
  "eval_steps": 500,
  "global_step": 2335,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.21401819154628143,
      "grad_norm": 0.6258543133735657,
      "learning_rate": 9.6e-05,
      "loss": 8.5292,
      "step": 100
    },
    {
      "epoch": 0.42803638309256287,
      "grad_norm": 0.5923788547515869,
      "learning_rate": 9.954546423849842e-05,
      "loss": 0.6104,
      "step": 200
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 0.5295755863189697,
      "learning_rate": 9.811440640474956e-05,
      "loss": 0.5616,
      "step": 300
    },
    {
      "epoch": 0.8560727661851257,
      "grad_norm": 0.6334670186042786,
      "learning_rate": 9.573426460545102e-05,
      "loss": 0.547,
      "step": 400
    },
    {
      "epoch": 1.06848582129481,
      "grad_norm": 0.5802378058433533,
      "learning_rate": 9.245198848804198e-05,
      "loss": 0.538,
      "step": 500
    },
    {
      "epoch": 1.2825040128410916,
      "grad_norm": 0.542007327079773,
      "learning_rate": 8.83323228112405e-05,
      "loss": 0.539,
      "step": 600
    },
    {
      "epoch": 1.496522204387373,
      "grad_norm": 0.5194388628005981,
      "learning_rate": 8.345653031794292e-05,
      "loss": 0.5092,
      "step": 700
    },
    {
      "epoch": 1.7105403959336543,
      "grad_norm": 0.4831957519054413,
      "learning_rate": 7.792078878151317e-05,
      "loss": 0.5176,
      "step": 800
    },
    {
      "epoch": 1.9245585874799358,
      "grad_norm": 0.5723257660865784,
      "learning_rate": 7.183429384463373e-05,
      "loss": 0.5149,
      "step": 900
    },
    {
      "epoch": 2.13697164258962,
      "grad_norm": 0.4924577474594116,
      "learning_rate": 6.531710507329815e-05,
      "loss": 0.4926,
      "step": 1000
    },
    {
      "epoch": 2.3509898341359015,
      "grad_norm": 0.4939904510974884,
      "learning_rate": 5.84977777137523e-05,
      "loss": 0.4987,
      "step": 1100
    },
    {
      "epoch": 2.5650080256821832,
      "grad_norm": 0.5168554782867432,
      "learning_rate": 5.151082686732224e-05,
      "loss": 0.5062,
      "step": 1200
    },
    {
      "epoch": 2.7790262172284645,
      "grad_norm": 0.47827669978141785,
      "learning_rate": 4.449407410371927e-05,
      "loss": 0.4992,
      "step": 1300
    },
    {
      "epoch": 2.993044408774746,
      "grad_norm": 0.5342671871185303,
      "learning_rate": 3.758592885238003e-05,
      "loss": 0.4936,
      "step": 1400
    },
    {
      "epoch": 3.20545746388443,
      "grad_norm": 0.5100580453872681,
      "learning_rate": 3.0922658197939816e-05,
      "loss": 0.4773,
      "step": 1500
    },
    {
      "epoch": 3.4194756554307117,
      "grad_norm": 0.5455294847488403,
      "learning_rate": 2.463569893467284e-05,
      "loss": 0.4738,
      "step": 1600
    },
    {
      "epoch": 3.633493846976993,
      "grad_norm": 0.5908148884773254,
      "learning_rate": 1.884906490115037e-05,
      "loss": 0.4926,
      "step": 1700
    },
    {
      "epoch": 3.8475120385232744,
      "grad_norm": 0.5332325100898743,
      "learning_rate": 1.367690073691179e-05,
      "loss": 0.4845,
      "step": 1800
    },
    {
      "epoch": 4.059925093632959,
      "grad_norm": 0.535828173160553,
      "learning_rate": 9.221230314686063e-06,
      "loss": 0.4794,
      "step": 1900
    },
    {
      "epoch": 4.27394328517924,
      "grad_norm": 0.46076518297195435,
      "learning_rate": 5.569944261615839e-06,
      "loss": 0.4889,
      "step": 2000
    },
    {
      "epoch": 4.487961476725522,
      "grad_norm": 0.5104554295539856,
      "learning_rate": 2.7950662667694637e-06,
      "loss": 0.4764,
      "step": 2100
    },
    {
      "epoch": 4.701979668271803,
      "grad_norm": 0.5923178791999817,
      "learning_rate": 9.513323730092505e-07,
      "loss": 0.4787,
      "step": 2200
    },
    {
      "epoch": 4.915997859818084,
      "grad_norm": 0.5040198564529419,
      "learning_rate": 7.511127748981439e-08,
      "loss": 0.4711,
      "step": 2300
    }
  ],
  "logging_steps": 100,
  "max_steps": 2335,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.04093535404032e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
